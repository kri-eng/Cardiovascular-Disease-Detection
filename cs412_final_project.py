# -*- coding: utf-8 -*-
"""CS412_Final_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14319z3eHf9XM-LpaP8tCOsxxfiXwP7Bp

**Student 1**

**Name:** Krish Patel

**NetID:** kpate400

**Student 2**

**Name:** Deep Patel

**NetID:** dpate329

In the first cell we have all the necessary libraries that we will require in order to perform our Machine learning task.
"""

# Importing Necessary libraries for the project.
import pandas as pd
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.metrics import classification_report

"""Connect to google drive in order to get the data, and store the data in a pandas dataframe."""

# Connecting Notebook to Google Drive.
from google.colab import drive
drive.mount('/content/drive')

# Checking the path.
!ls /content/drive/MyDrive/CS412_Final_Project/

# Getting the path to the .csv datafile
path = "/content/drive/MyDrive/CS412_Final_Project/heart_2020_cleaned.csv"

# Get the data into the pandas dataframe.
heart_df = pd.read_csv(path)

"""In the next few steps we will understand and clean the data a bit more in order to prepare it for usage in the ML task."""

# Shape of data.
heart_df.shape

# Get the information of the dataset.
heart_df.info()

# Printing the data.
heart_df

# Replace the Yes/No to 1/0.
# Get the columsn to make this correction in:
columns_to_replace = ['HeartDisease', 'Smoking', 'AlcoholDrinking', 'Stroke', 'DiffWalking',
                       'Diabetic', 'PhysicalActivity', 'Asthma', 'KidneyDisease', 'SkinCancer']

# Make the changes.
heart_df[columns_to_replace] = heart_df[columns_to_replace].replace({'Yes': 1, 'No': 0, 'No, borderline diabetes': 0, 'Yes (during pregnancy)': 1})

# Printing the heart_df
heart_df

# Now encode the columns with string object as a numeric ones.
label_encoder = LabelEncoder()
heart_df['GenHealth'] = label_encoder.fit_transform(heart_df['GenHealth'])

heart_df

# Now encode the columns with string object as a numeric ones.
label_encoder = LabelEncoder()
heart_df['Sex'] = label_encoder.fit_transform(heart_df['Sex'])

heart_df

# Now encode the columns with string object as a numeric ones.
label_encoder = LabelEncoder()
heart_df['Race'] = label_encoder.fit_transform(heart_df['Race'])

heart_df

# Remove ' or older'
heart_df['AgeCategory'] = heart_df['AgeCategory'].str.replace(' or older', '')

# Split into 'StartAge' and 'EndAge'
heart_df[['StartAge', 'EndAge']] = heart_df['AgeCategory'].str.split('-', expand=True)

# Calculate the midpoint and replace 'AgeCategory'
heart_df['AgeCategory'] = heart_df[['StartAge', 'EndAge']].astype(float).mean(axis=1).astype(int)

# Drop the 'StartAge' and 'EndAge' columns if no longer needed
heart_df = heart_df.drop(['StartAge', 'EndAge'], axis=1)

# Print the df.
heart_df

"""Creating logistic regression class in to generate the model fro predicting the Heart Disease."""

import numpy as np
from sklearn.model_selection import train_test_split

class LogisticRegression:
    def __init__(self, learning_rate=0.01, max_iterations=1000):
        self.learning_rate = learning_rate
        self.max_iterations = max_iterations
        self.weights = None
        self.bias = None
        self.train_loss = []
        self.val_loss = []

    def sigmoid(self, z):
        return 1.0 / (1 + np.exp(-z))

    def prob(self, x, w, b):
        return self.sigmoid(np.dot(x, w) + b)

    def loss(self, w, x, y_prob, y_true, lambda_):
        # Log prob.
        log_prob = ((-1) / (y_true.size)) * (
            np.sum((y_true * (np.log(y_prob))) + ((1 - y_true) * (np.log(1 - y_prob)))))
        # Regularization loss.
        reg_loss = (lambda_ / 2) * (np.linalg.norm(w) ** 2)
        # Cross Entropy loss.
        cross_entropy_loss = log_prob + reg_loss
        # Return the entropy.
        return cross_entropy_loss

    def grad_w_b(self, x, weights, y_prob, y_true, lambda_):
        # Calculate gradients for weights and bias
        grad_w = (1 / y_true.size) * np.dot(x.T, (y_prob - y_true)) + lambda_ * weights
        grad_b = (1 / y_true.size) * np.sum(y_prob - y_true)
        return grad_w, grad_b

    def fit(self, x, y_true, x_val, y_val, learning_rate, lambda_, max_iter, verbose=0):
        self.weights = np.random.normal(0, 1, x.shape[1])
        self.bias = np.random.normal(0, 1, 1)

        # Iteration tracker.
        i = 0

        # Loop till i is not equal to maxIter.
        grad_norm = float("inf")
        while i < max_iter:
            # Calculate the y_prob.
            y_prob = self.prob(x, self.weights, self.bias)
            # Calculate the gradients.
            grad_w, grad_b = self.grad_w_b(x, self.weights, y_prob, y_true, lambda_)

            # Update the weights and bias.
            self.weights -= (learning_rate * grad_w)
            self.bias -= (learning_rate * grad_b)

            # Calculate the loss, gradient norm, weights norm.
            loss_val = self.loss(self.weights, x, y_prob, y_true, lambda_)
            self.train_loss.append(loss_val)

            # Compute the validation loss.
            y_val_prob = self.prob(x_val, self.weights, self.bias)
            val_loss = self.loss(self.weights, x_val, y_val_prob, y_val, lambda_)
            self.val_loss.append(val_loss)

            grad_norm = np.linalg.norm(grad_w)
            weights_norm = np.linalg.norm(self.weights)

            # Stopping condition for gradient norm.
            if grad_norm < 0.1:
                break

            if verbose:  # verbose is used for debugging purposes
                # print iteration number, loss, l2 norm of gradients, l2 norm of weights
                print(
                    f"Iteration - {i}: Loss - {loss_val}, Gradient Norm - {grad_norm}, Weights Norm - {weights_norm}")

            # Update the iteration.
            i += 1

        return self.weights, self.bias

    def accuracy(self, x, y_true):
        return np.sum((self.prob(x, self.weights, self.bias) > 0.5).astype(float) == y_true) / y_true.shape[0]

    def predict(self, X):
        linear_combination = np.dot(X, self.weights) + self.bias
        predictions = self.sigmoid(linear_combination)
        # Convert probabilities to binary predictions (0 or 1)
        return np.where(predictions >= 0.5, 1, 0)

"""In this section we will split the data into train, test and validation set and use them in order to predict the heart disease status using the logistic regression model."""

# Define features (X) and target variable (y)
X = heart_df.drop('HeartDisease', axis=1)
y = heart_df['HeartDisease']

# Split the data into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Initialize and train the logistic regression model
lr_model = LogisticRegression(learning_rate=0.01, max_iterations=1000)
weights, bias = lr_model.fit(X_train, y_train, X_val, y_val, learning_rate=0.01, lambda_=0.01, max_iter=1000, verbose=0)

# Calculate the accuracy on training set.
training_accuracy = lr_model.accuracy(X_train, y_train)
print(f"Accuracy on Training Set: {training_accuracy}")

# Calculate the accuracy on Validation set.
validation_accuracy = lr_model.accuracy(X_val, y_val)
print(f"Accuracy on Validation Set: {validation_accuracy}")

# Calculate the prediction on test set.
predictions = lr_model.predict(X_test)

# Calculate accuracy on the test set
test_accuracy = lr_model.accuracy(X_test, y_test)
print(f"Accuracy on Test Set: {test_accuracy}")

# Plot training and validation losses over iterations
import matplotlib.pyplot as plt

train_losses = lr_model.train_loss
val_losses = lr_model.val_loss

plt.plot(range(len(train_losses)), train_losses, label='Training Loss', linewidth=0.5)
plt.plot(range(len(val_losses)), val_losses, label='Validation Loss', linewidth=0.5)
plt.xlabel('Iteration')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""In order to improve the accuracy we will compare a few learning rates and their accuraries and use the one that has the best accuracy.

"""

best_model = None
best_val = -1
for lr in [0.001, 0.0001, 0.00001]:
    lr_model_2 = LogisticRegression(learning_rate=lr, max_iterations=1000)
    weights, bias = lr_model_2.fit(X_train, y_train, X_val, y_val, learning_rate=lr, lambda_=0.01, max_iter=1000, verbose=0)
    # Calculate the accuracy
    val_acc = lr_model_2.accuracy(X_train, y_train)
    if val_acc > best_val:
        best_val = val_acc
        best_model = lr_model_2

# Calculate the accuracy on training set.
training_accuracy = lr_model_2.accuracy(X_train, y_train)
print(f"Accuracy on Training Set: {training_accuracy}")

# Calculate the accuracy on Validation set.
validation_accuracy = lr_model_2.accuracy(X_val, y_val)
print(f"Accuracy on Validation Set: {validation_accuracy}")

# Calculate accuracy on the test set
test_accuracy_2 = lr_model_2.accuracy(X_test, y_test)
print(f"Accuracy on Test Set: {test_accuracy_2}")

train_losses = best_model.train_loss
val_losses = best_model.val_loss

plt.plot(range(len(train_losses)), train_losses, label='Training Loss')
plt.plot(range(len(val_losses)), val_losses, label='Validation Loss')
plt.xlabel('Iteration')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""Here we have the best model that can be used after the hyperparameter tuning, and here is the best accuracy that can be acheived with this model."""

if(test_accuracy > test_accuracy_2):
    print(f"The highest test accuracy achieved with this model: {test_accuracy}")
else:
    print(f"The highest test accuracy achieved with this model: {test_accuracy_2}")